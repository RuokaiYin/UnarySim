{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummaryX import summary\n",
    "from UnarySim.sw.kernel.linear import UnaryLinear\n",
    "from UnarySim.sw.bitstream.gen import RNG, SourceGen, BSGen\n",
    "from UnarySim.sw.metric.metric import ProgressivePrecision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wudidaizi/Project/stochasticSim/pytorchSim\n",
      "/Users/wudidaizi/Project/stochasticSim/pytorchSim/saved_model_state_dict_8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = \"/Users/wudidaizi/Project/stochasticSim/pytorchSim\"\n",
    "print(cwd)\n",
    "model_path = cwd+\"/saved_model_state_dict_8\"\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data loader\n",
    "transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc1_drop): Dropout(p=0.6, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2_drop): Dropout(p=0.6, inplace=False)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.conv1(x)\n",
    "        x = torch.clamp(x, -1, 1)\n",
    "        x = F.avg_pool2d(x, (2, 2))\n",
    "        x = F.relu(x)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = self.conv2(x)\n",
    "        x = torch.clamp(x, -1, 1)\n",
    "        x = F.avg_pool2d(x, (2, 2))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.clamp(x, -1, 1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.clamp(x, -1, 1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32, 512)\n",
    "        self.fc1_drop = nn.Dropout(0.6)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_drop = nn.Dropout(0.6)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)        \n",
    "        x = torch.clamp(x, -1, 1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_drop(x)\n",
    "        x = torch.clamp(x, -1, 1)\n",
    "        return F.log_softmax(self.fc3(x), dim=1)\n",
    "    \n",
    "model = Net()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc1_drop): Dropout(p=0.6, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2_drop): Dropout(p=0.6, inplace=False)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data[0].to(device), data[1].to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "#     print(images.size())\n",
    "# print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1024])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(1024, 512)\n",
    "fc.weight = model.fc1.weight\n",
    "fc.bias = model.fc1.bias\n",
    "ufc = UnaryLinear(1024, 512, 256, model.fc1.weight, model.fc1.bias)\n",
    "print(fc.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2969,  0.9102, -0.4883, -0.9414, -0.3828, -0.3711, -0.3086,  0.7148,\n",
      "         -0.4961, -1.0000, -1.0000, -0.2109,  0.3359,  1.0000, -0.0195,  0.0664,\n",
      "          0.2852,  0.5312,  1.0000,  0.6914, -0.6523, -0.4883,  0.0391, -0.1133,\n",
      "          0.4844, -0.1758, -1.0000,  0.1758, -0.2578,  0.0664, -0.9297, -0.7383,\n",
      "          0.6055,  0.0781, -0.9648, -1.0000,  0.0586,  0.5977, -0.6328,  0.2031,\n",
      "         -0.2070, -1.0000, -0.9102,  0.6875,  0.6094,  0.5117, -1.0000, -0.0547,\n",
      "          0.7383,  0.4492, -0.7539, -1.0000, -0.1250,  0.7656,  1.0000,  0.0742,\n",
      "         -0.2461, -1.0000,  0.4141, -0.1016, -0.0703, -0.2109,  0.2969,  0.8633,\n",
      "          1.0000,  0.6523, -1.0000,  0.5000, -0.1445,  1.0000, -0.3203, -0.0859,\n",
      "          0.7891, -1.0000,  1.0000,  0.0234,  0.2812,  0.2227, -1.0000, -0.9609,\n",
      "         -0.4648, -0.6914, -0.4648,  0.3828,  1.0000, -1.0000,  0.3008, -0.1289,\n",
      "         -1.0000,  0.4727,  0.2188, -0.6211, -0.2812, -1.0000, -0.1406, -0.3047,\n",
      "         -1.0000, -1.0000, -0.9844,  0.0703, -1.0000, -0.5664,  1.0000, -1.0000,\n",
      "         -0.7969, -0.9766, -0.6641, -0.3672, -0.0234, -0.0273, -0.1211,  0.3516,\n",
      "         -1.0000,  0.1641, -1.0000,  1.0000,  0.0508, -0.3359,  1.0000,  1.0000,\n",
      "          0.0195, -0.1289, -0.7266,  1.0000, -0.2578, -0.4141, -1.0000, -0.9648,\n",
      "          1.0000,  0.3125, -0.5039, -1.0000,  0.2617,  0.5000,  0.0039,  0.4766,\n",
      "         -0.6094,  0.0938,  1.0000,  1.0000,  1.0000,  0.2812, -1.0000, -0.8047,\n",
      "          0.2188, -0.5664, -1.0000, -0.6211, -0.5352, -1.0000, -1.0000, -1.0000,\n",
      "         -0.6875, -0.2070, -0.2422, -0.0078, -1.0000,  1.0000, -0.7305,  0.4883,\n",
      "          1.0000,  0.1250,  0.2227, -1.0000,  0.4961,  0.8672, -1.0000, -1.0000,\n",
      "          0.2109, -0.1016,  0.1914, -0.5781,  0.5742,  1.0000, -0.7539, -1.0000,\n",
      "          1.0000,  0.6250,  0.4414, -0.2930, -1.0000, -0.7539, -0.0859,  0.9492,\n",
      "          0.7773, -1.0000,  1.0000, -0.0039,  0.6367, -1.0000,  0.2188, -0.5664,\n",
      "          1.0000,  0.0586,  1.0000, -0.9219,  1.0000,  0.5078, -1.0000, -0.3906,\n",
      "         -0.1133,  1.0000,  1.0000,  0.7812,  0.3242, -1.0000, -0.5039,  0.2031,\n",
      "         -1.0000,  0.1719,  1.0000, -0.4297, -0.3516,  1.0000,  1.0000, -0.3867,\n",
      "          0.8242, -1.0000,  0.3203,  0.4336, -1.0000, -1.0000,  0.5469,  1.0000,\n",
      "         -0.1523,  0.1172,  0.4258,  0.1953,  1.0000, -0.9102, -0.0547, -0.0859,\n",
      "         -0.2188, -0.2070,  0.8008,  0.7734,  0.1680, -0.5898,  1.0000, -0.7461,\n",
      "          1.0000, -0.1992, -0.4375, -0.2773,  0.6992, -1.0000,  0.6367,  0.3242,\n",
      "         -0.3359,  0.4258, -0.3086,  0.2695,  1.0000,  0.2305, -0.6914, -0.7695,\n",
      "         -0.6719,  1.0000, -0.0820, -0.5820, -1.0000,  0.5391,  0.3594,  0.4531,\n",
      "         -0.2070, -1.0000,  0.7305, -0.4727,  1.0000,  1.0000,  0.2891, -0.5742,\n",
      "         -0.0156, -0.4688,  0.5859, -0.8438, -0.5938,  1.0000,  0.6680, -1.0000,\n",
      "          0.1875,  0.8398, -0.0781, -0.3750, -1.0000,  0.7344,  0.0469,  0.9023,\n",
      "          1.0000,  0.4453,  0.1758,  1.0000, -1.0000, -0.8359,  0.8711, -1.0000,\n",
      "          0.0781, -0.1680, -1.0000, -0.3320,  1.0000,  0.1719,  0.4648, -0.0195,\n",
      "          0.3438,  0.6133, -0.5547,  1.0000,  0.4766,  1.0000, -1.0000,  0.2461,\n",
      "          0.1445, -0.1914, -0.1641, -1.0000,  0.0977, -0.0664, -0.5703,  1.0000,\n",
      "          1.0000, -1.0000,  0.4375,  0.1953,  0.4766,  1.0000,  1.0000, -1.0000,\n",
      "         -0.0586,  0.0625, -0.2852,  1.0000,  0.0625,  0.2031, -0.1758,  0.5586,\n",
      "          0.1484,  1.0000,  0.6250, -1.0000,  0.5000,  0.4766,  1.0000, -0.9961,\n",
      "          0.2930,  0.3125,  0.7617, -0.2031,  0.1250, -0.8555, -0.6250,  0.1562,\n",
      "         -0.2656, -0.1992,  0.0977,  1.0000, -0.2266, -0.4297,  0.9883, -0.0859,\n",
      "          0.8594,  1.0000,  1.0000, -0.3438,  0.3203, -0.3555, -1.0000, -0.0781,\n",
      "         -0.2891,  1.0000, -0.4180, -0.3008, -1.0000, -1.0000,  0.8750, -0.7305,\n",
      "          0.0156,  0.0352,  0.2227, -0.1328, -0.0195, -0.8867,  0.5781, -0.2148,\n",
      "         -0.2227, -0.6797, -0.5273,  0.3438,  0.1562,  0.5625, -0.4414, -0.6836,\n",
      "         -1.0000,  0.2734,  0.2930, -0.8203, -1.0000,  0.9922,  0.1641, -0.4531,\n",
      "          0.6211,  0.3242,  1.0000,  0.8594,  0.1094, -1.0000,  1.0000, -0.1172,\n",
      "         -1.0000, -1.0000, -0.8320, -1.0000, -1.0000, -0.2930,  1.0000, -0.7891,\n",
      "         -0.0391,  0.3555, -0.4258, -0.2461, -0.6328, -1.0000,  0.6641, -0.9062,\n",
      "          0.2422,  0.1016,  0.5234, -0.6094, -0.3477,  1.0000,  0.1992, -0.7695,\n",
      "          1.0000, -0.6211, -0.0703, -0.3438, -0.0742,  0.8516, -0.4805,  0.9023,\n",
      "          0.5312,  0.8242, -1.0000, -0.0430,  0.0000,  0.0391,  1.0000,  0.0742,\n",
      "          1.0000, -0.2227,  1.0000, -0.2539, -1.0000, -0.2930, -0.1758,  0.3047,\n",
      "          0.5977, -1.0000,  0.9688,  0.5742,  1.0000,  1.0000,  0.7578, -1.0000,\n",
      "         -1.0000,  1.0000,  0.0781, -0.8242,  0.8711, -1.0000,  0.9219,  1.0000,\n",
      "          0.8945,  0.6836,  0.1484,  0.1250, -0.3359, -0.0039, -0.0078,  0.5234,\n",
      "         -0.1133, -0.9414, -0.6289, -1.0000,  0.5352,  0.4648, -0.3438,  0.7812,\n",
      "          1.0000, -0.1914,  0.8828,  0.5586,  0.3945,  0.4141, -0.1172, -1.0000,\n",
      "         -0.2383,  0.1055, -1.0000, -0.9922,  1.0000, -0.0117, -0.5938, -0.8672,\n",
      "         -0.6250,  0.1719,  0.8633,  0.5859, -0.1992, -1.0000, -1.0000, -0.4258]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "iVec = (((torch.rand(1, 1024) * 2 - 1)/4)*256).floor()/256\n",
    "# print(inVec)\n",
    "oVec = fc(iVec)\n",
    "oVec = oVec.clamp_(-1.,1.).mul_(256).floor()/256\n",
    "# print(inVec)\n",
    "print(oVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input error:  tensor(-0.0039) tensor(0.0039)\n",
      "output count: tensor([[ 0.6875, -0.0273,  0.6680,  0.9883,  0.6445,  0.6680,  0.6875,  0.1797,\n",
      "          0.8086,  0.4180,  0.6953,  0.6250,  0.3008,  0.0000,  0.4570,  0.5391,\n",
      "          0.4141,  0.2383,  0.0000,  0.2578,  0.7812,  0.8125,  0.4180,  0.5586,\n",
      "          0.4336,  0.6367,  0.8086,  0.5352,  0.5039,  0.6406,  0.9883,  0.8867,\n",
      "          0.0938,  0.5117,  0.9727,  0.7695,  0.5430,  0.1992,  0.8867,  0.4258,\n",
      "          0.6328,  0.8867,  1.0586,  0.1914,  0.2344,  0.3945,  0.7109,  0.5547,\n",
      "          0.1797,  0.4102,  0.9219,  0.6719,  0.5977,  0.2305,  0.0000,  0.4648,\n",
      "          0.7266,  0.2227,  0.3984,  0.5938,  0.5078,  0.6836,  0.4062,  0.0273,\n",
      "          0.0000,  0.2969,  0.6992,  0.3320,  0.4453,  0.0000,  0.7773,  0.5742,\n",
      "          0.1367,  0.4727,  0.0000,  0.6250,  0.4180,  0.3633,  0.7188,  1.0195,\n",
      "          0.8203,  0.9023,  0.7852,  0.2969,  0.0000,  0.6328,  0.3750,  0.7422,\n",
      "          0.2148,  0.3281,  0.5273,  0.7969,  0.7773,  0.5820,  0.5781,  0.5938,\n",
      "          0.8398,  0.9609,  1.0664,  0.5469,  0.5508,  0.8398,  0.0000,  0.8594,\n",
      "          1.1250,  1.0039,  0.7695,  0.5859,  0.5586,  0.4961,  0.5312,  0.4062,\n",
      "          0.8672,  0.5273,  0.9023,  0.0000,  0.6367,  0.7500,  0.0000,  0.0000,\n",
      "          0.5977,  0.6914,  1.0430,  0.0000,  0.7148,  0.7188,  0.5547,  1.0664,\n",
      "          0.0000,  0.3906,  0.8398,  0.5352,  0.4922,  0.2148,  0.5156,  0.3086,\n",
      "          0.8359,  0.3711,  0.0000,  0.0000,  0.0000,  0.5312,  0.7734,  1.0039,\n",
      "          0.4648,  0.7891,  0.6250,  0.8672,  0.7266,  0.7188,  1.1562,  0.7852,\n",
      "          0.8555,  0.6094,  0.6406,  0.6016,  0.0000,  0.0000,  0.9570,  0.4023,\n",
      "          0.0000,  0.4922,  0.4766,  0.8516,  0.3477,  0.1328,  0.4180,  0.5586,\n",
      "          0.4844,  0.3945,  0.5156,  0.7578,  0.1992,  0.0000,  0.9102,  0.1406,\n",
      "          0.0000,  0.2695,  0.2539,  0.7891,  0.9531,  1.0117,  0.6680, -0.0352,\n",
      "          0.0820,  0.9531,  0.0000,  0.5820,  0.2305,  0.5117,  0.4961,  0.7695,\n",
      "          0.0000,  0.6016,  0.0000,  0.9219,  0.0000,  0.2227,  0.8320,  0.6445,\n",
      "          0.6133,  0.0000,  0.0000,  0.1211,  0.3398,  0.8789,  0.8945,  0.5078,\n",
      "          0.8164,  0.3906,  0.0000,  0.6992,  0.7344,  0.0000,  0.0000,  0.7773,\n",
      "          0.1758,  0.9141,  0.3086,  0.3789,  0.6406,  0.0820,  0.3125,  0.0000,\n",
      "          0.6211,  0.4297,  0.3828,  0.5273,  0.0000,  0.9375,  0.6484,  0.6602,\n",
      "          0.6406,  0.5977,  0.1992,  0.1328,  0.5430,  0.6016,  0.0000,  0.9062,\n",
      "          0.0000,  0.6133,  0.8281,  0.7617,  0.2148,  0.3477,  0.1914,  0.3555,\n",
      "          0.7891,  0.3164,  0.6992,  0.5078,  0.0000,  0.3398,  0.8125,  0.8203,\n",
      "          0.8633,  0.0000,  0.3789,  0.8398,  1.0742,  0.3750,  0.3594,  0.2578,\n",
      "          0.6094,  0.0000,  0.1367,  0.7422,  0.0000,  0.0000,  0.3164,  0.8672,\n",
      "          0.4844,  0.7852,  0.3047,  0.9375,  0.7383,  0.0000,  0.0703,  0.7852,\n",
      "          0.3945,  0.1523,  0.5508,  0.6250,  0.5977,  0.1875,  0.5000,  0.0977,\n",
      "          0.0000,  0.3047,  0.3438,  0.0000,  0.4023,  1.0664,  0.1289,  0.0000,\n",
      "          0.5820,  0.5273,  0.3555,  0.7695,  0.0000,  0.5234,  0.3242,  0.6445,\n",
      "          0.2930,  0.2656,  0.8047,  0.0000,  0.4336,  0.0000,  0.6875,  0.4062,\n",
      "          0.4766,  0.5898,  0.6484,  0.9180,  0.5586,  0.5156,  0.6680,  0.0000,\n",
      "          0.0000,  0.0000,  0.1875,  0.4219,  0.2969,  0.0000,  0.0000,  0.0000,\n",
      "          0.5781,  0.6328,  0.6875,  0.0000,  0.4766,  0.4766,  0.6055,  0.3281,\n",
      "          0.4609,  0.0000,  0.1523,  0.5391,  0.2695,  0.2500,  0.0000,  1.0117,\n",
      "          0.3984,  0.5664,  0.2383,  0.7109,  0.5391,  1.0000,  0.8320,  0.4922,\n",
      "          0.6953,  0.5898,  0.5391,  0.0000,  0.6562,  0.8320,  0.0078,  0.5938,\n",
      "          0.1406, -0.0625, -0.0312,  0.6953,  0.4023,  0.6055,  0.7930,  0.6406,\n",
      "          0.7383,  0.0000,  0.6602,  0.8359,  0.5234,  0.0000,  0.1250,  0.9102,\n",
      "          0.4062,  0.4805,  0.5625,  0.6094,  0.5469,  0.9102,  0.2266,  0.5820,\n",
      "          0.6797,  1.0430,  0.7773,  0.3711,  0.4766,  0.2812,  0.7812,  0.8711,\n",
      "          0.4531,  0.3125,  0.5352,  0.9180,  0.3906,  0.0078,  0.5898,  0.7852,\n",
      "          0.2266,  0.5312,  0.0000,  0.1406,  0.5547,  0.4883,  0.0000,  0.5859,\n",
      "          0.4336,  1.0078,  0.8164,  0.0742,  0.4414,  0.6211,  0.0000,  1.0117,\n",
      "          0.6016,  0.4023,  0.6836,  0.6523,  0.7266,  0.8750,  0.1953,  0.8477,\n",
      "          0.3555,  0.5469,  0.2852,  0.9453,  0.5234,  0.0000,  0.3828,  0.9688,\n",
      "          0.0000,  0.8359,  0.5820,  0.7773,  0.6914,  0.0039,  0.6445,  0.0977,\n",
      "          0.3047,  0.1758,  0.7109,  0.5781,  0.6758,  0.4961,  0.0000,  0.5586,\n",
      "          0.0000,  0.4492,  0.0000,  0.8047,  0.8555,  0.6602,  0.5859,  0.5078,\n",
      "          0.0977,  0.9414, -0.0312,  0.2383,  0.0000,  0.0000,  0.2422,  0.9180,\n",
      "          0.4219,  0.0000,  0.4609,  0.8906,  0.1250,  1.0000,  0.0781,  0.0000,\n",
      "          0.1055,  0.1211,  0.4219,  0.5234,  0.7109,  0.5508,  0.6133,  0.0898,\n",
      "          0.6562,  0.8750,  0.7305,  1.0820,  0.3125,  0.2031,  0.6914,  0.2109,\n",
      "          0.0000,  0.5977,  0.0859,  0.1797,  0.2812,  0.3555,  0.6680,  0.6133,\n",
      "          0.6953,  0.4609,  1.0195,  1.0664,  0.0000,  0.6406,  0.8203,  1.0508,\n",
      "          0.7852,  0.5938,  0.1367,  0.2617,  0.6797,  0.9648,  0.3633,  0.7266]])\n"
     ]
    }
   ],
   "source": [
    "iVecSource = SourceGen(iVec, bitwidth=8, mode=\"bipolar\").Gen()\n",
    "iVecRNG = RNG(8, 1, \"Sobol\").Out()\n",
    "iVecBS = BSGen(iVecSource, iVecRNG)\n",
    "\n",
    "iVecPP = ProgressivePrecision(iVec, mode=\"bipolar\")\n",
    "oVecPP = ProgressivePrecision(oVec, mode=\"bipolar\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    idx = torch.zeros(iVecSource.size()).type(torch.long)\n",
    "    for i in range(256):\n",
    "        iBS = iVecBS.Gen(idx + i)\n",
    "        iVecPP.Monitor(iBS)\n",
    "        oVecU = ufc(iBS)\n",
    "#         oVecPP.Monitor(oVec)\n",
    "    print(\"input error: \", min(min(iVecPP.Report())), max(max(iVecPP.Report())))\n",
    "#     print(\"output error:\", min(min(oVecPP.Report())), max(max(oVecPP.Report())))\n",
    "    outProb = (oVecU-1024*128)/256\n",
    "    outProb.clamp_(-1.,1.)\n",
    "    print(\"output count:\", outProb - oVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
