{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from UnarySim.sw.kernel.nn_utils import *\n",
    "from UnarySim.sw.kernel.linear import *\n",
    "from UnarySim.sw.kernel.relu import UnaryReLU\n",
    "from UnarySim.sw.bitstream.gen import RNG, SourceGen, BSGen\n",
    "from UnarySim.sw.metric.metric import ProgressiveError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project\\Anaconda3\\Lib\\site-packages\\UnarySim\\sw\\test\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data loader\n",
    "transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test binary model clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.080000 %\n"
     ]
    }
   ],
   "source": [
    "model_path = cwd+\"\\saved_model_state_dict_8_clamp\"\n",
    "model_clamp = MLP3_clamp_eval()\n",
    "model_clamp.to(device)\n",
    "model_clamp.load_state_dict(torch.load(model_path))\n",
    "model_clamp.eval()\n",
    "model_clamp.to(device)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_clamp(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test unary model nonscaled addition - clamp binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 117.79590392112732 seconds ---\n",
      "100 images are done!!!\n",
      "--- 233.86700177192688 seconds ---\n",
      "200 images are done!!!\n",
      "--- 349.72913002967834 seconds ---\n",
      "300 images are done!!!\n",
      "--- 467.6069815158844 seconds ---\n",
      "400 images are done!!!\n",
      "--- 584.670756816864 seconds ---\n",
      "500 images are done!!!\n",
      "--- 700.9458310604095 seconds ---\n",
      "600 images are done!!!\n",
      "--- 817.465390920639 seconds ---\n",
      "700 images are done!!!\n",
      "--- 933.5371603965759 seconds ---\n",
      "800 images are done!!!\n",
      "--- 1050.2224917411804 seconds ---\n",
      "900 images are done!!!\n",
      "--- 1169.4167454242706 seconds ---\n",
      "1000 images are done!!!\n",
      "--- 1285.9719319343567 seconds ---\n",
      "1100 images are done!!!\n",
      "--- 1402.059403181076 seconds ---\n",
      "1200 images are done!!!\n",
      "--- 1522.833696603775 seconds ---\n",
      "1300 images are done!!!\n",
      "--- 1639.7439551353455 seconds ---\n",
      "1400 images are done!!!\n",
      "--- 1758.0403072834015 seconds ---\n",
      "1500 images are done!!!\n",
      "--- 1875.058111667633 seconds ---\n",
      "1600 images are done!!!\n",
      "--- 1994.41672539711 seconds ---\n",
      "1700 images are done!!!\n",
      "--- 2114.304099559784 seconds ---\n",
      "1800 images are done!!!\n",
      "--- 2231.7823145389557 seconds ---\n",
      "1900 images are done!!!\n",
      "--- 2348.558178663254 seconds ---\n",
      "2000 images are done!!!\n",
      "--- 2467.6346566677094 seconds ---\n",
      "2100 images are done!!!\n",
      "--- 2590.3540790081024 seconds ---\n",
      "2200 images are done!!!\n",
      "--- 2714.5545856952667 seconds ---\n",
      "2300 images are done!!!\n",
      "--- 2840.400681734085 seconds ---\n",
      "2400 images are done!!!\n",
      "--- 2960.4659020900726 seconds ---\n",
      "2500 images are done!!!\n",
      "--- 3082.3416447639465 seconds ---\n",
      "2600 images are done!!!\n",
      "--- 3201.3197515010834 seconds ---\n",
      "2700 images are done!!!\n",
      "--- 3320.8292367458344 seconds ---\n",
      "2800 images are done!!!\n",
      "--- 3439.5083286762238 seconds ---\n",
      "2900 images are done!!!\n"
     ]
    }
   ],
   "source": [
    "correct_binary = 0\n",
    "correct_unary = 0\n",
    "\n",
    "bitwidth = 8\n",
    "total = 0\n",
    "\n",
    "# binary MLP3_clamp weight init\n",
    "rng = \"Sobol\"\n",
    "rng_dim = 1\n",
    "relu_buf_dep = 4\n",
    "mode = \"bipolar\"\n",
    "scaled = False\n",
    "bias = True\n",
    "sample_cnt = 20000\n",
    "\n",
    "start_cnt = 0\n",
    "current_index = 0\n",
    "\n",
    "cycle_correct = torch.zeros(2**(bitwidth)).to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        if current_index < start_cnt:\n",
    "            current_index = current_index + 1\n",
    "            continue\n",
    "        current_index = current_index + 1\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # reference binary mlp\n",
    "        outputs_binary = model_clamp(images)\n",
    "        _, predicted_binary = torch.max(outputs_binary.data, 1)\n",
    "        correct_binary += (predicted_binary == labels).sum().item()\n",
    "        \n",
    "#         print(model_clamp.fc1_out.min().item(), model_clamp.fc1_out.max().item())\n",
    "#         print(model_clamp.fc2_out.min().item(), model_clamp.fc2_out.max().item())\n",
    "#         print(model_clamp.fc3_out.min().item(), model_clamp.fc3_out.max().item())\n",
    "\n",
    "\n",
    "        # unary part\n",
    "        # input image check\n",
    "        image = images.view(-1, 32*32)\n",
    "        image_SRC = SourceGen(image, bitwidth=bitwidth, mode=mode)().to(device)\n",
    "        image_RNG = RNG(bitwidth, rng_dim, rng)().to(device)\n",
    "        image_BSG = BSGen(image_SRC, image_RNG).to(device)\n",
    "        image_ERR = ProgressiveError(image, mode=mode).to(device)\n",
    "        \n",
    "        # unary mlp is decomposed into separate layers\n",
    "        fc1_unary = GainesLinear1(32*32, 512, model_clamp.fc1.weight.data, model_clamp.fc1.bias.data, \n",
    "                                 bitwidth=bitwidth, mode=mode, scaled=scaled, bias=bias, depth=bitwidth, rng_idx=2).to(device)\n",
    "        fc1_ERR = ProgressiveError(model_clamp.fc1_out, mode=mode).to(device)\n",
    "        \n",
    "        fc2_unary = GainesLinear1(512, 512, model_clamp.fc2.weight.data, model_clamp.fc2.bias.data, \n",
    "                                 bitwidth=bitwidth, mode=mode, scaled=scaled, bias=bias, depth=bitwidth, rng_idx=3).to(device)\n",
    "        fc2_ERR = ProgressiveError(model_clamp.fc2_out, mode=mode).to(device)\n",
    "\n",
    "        fc3_unary = GainesLinear1(512, 10, model_clamp.fc3.weight.data, model_clamp.fc3.bias.data, \n",
    "                                 bitwidth=bitwidth, mode=mode, scaled=scaled, bias=bias, depth=bitwidth, rng_idx=4).to(device)\n",
    "        fc3_ERR = ProgressiveError(model_clamp.fc3_out, mode=mode).to(device)\n",
    "        \n",
    "        relu1_unary = UnaryReLU(buf_dep=relu_buf_dep, bitwidth=bitwidth, rng=rng).to(device)\n",
    "        relu1_ERR = ProgressiveError(model_clamp.relu1_out, mode=mode).to(device)\n",
    "        \n",
    "        relu2_unary = UnaryReLU(buf_dep=relu_buf_dep, bitwidth=bitwidth, rng=rng).to(device)\n",
    "        relu2_ERR = ProgressiveError(model_clamp.relu2_out, mode=mode).to(device)\n",
    "        \n",
    "        if total%100 == 0:\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            print(total, \"images are done!!!\")\n",
    "\n",
    "#         print(current_index, \"-th image with label\", labels.item(), \", total image count\", total)\n",
    "        for i in range(2**(bitwidth)):\n",
    "            idx = torch.zeros(image_SRC.size()).type(torch.long).to(device)\n",
    "            image_bs = image_BSG(idx + i)\n",
    "            image_ERR.Monitor(image_bs)\n",
    "            # print(image_bs.shape)\n",
    "            # fc1\n",
    "            fc1_unary_out   = fc1_unary(image_bs)\n",
    "#             fc1_ERR.Monitor(fc1_unary_out)\n",
    "            # print(fc1_unary_out.shape)\n",
    "            # relu1\n",
    "            relu1_unary_out = relu1_unary(fc1_unary_out)\n",
    "#             relu1_ERR.Monitor(relu1_unary_out)\n",
    "            # print(relu1_unary_out.shape)\n",
    "            # fc2\n",
    "            fc2_unary_out   = fc2_unary(relu1_unary_out)\n",
    "#             fc2_ERR.Monitor(fc2_unary_out)\n",
    "            # print(fc2_unary_out.shape)\n",
    "            # relu2\n",
    "            relu2_unary_out = relu2_unary(fc2_unary_out)\n",
    "#             relu2_ERR.Monitor(relu2_unary_out)\n",
    "            # print(relu2_unary_out.shape)\n",
    "            # fc3\n",
    "            fc3_unary_out   = fc3_unary(relu2_unary_out)\n",
    "            fc3_ERR.Monitor(fc3_unary_out)\n",
    "            # print(fc3_unary_out.shape)\n",
    "            \n",
    "            _, predicted_unary = torch.max(fc3_ERR()[0], 1)\n",
    "            if predicted_unary == labels:\n",
    "#                 print(current_index, \"-th image succeeds.\")\n",
    "#                 print(current_index, \"-th image with label\", labels.item(), \", total image count\", total)\n",
    "#                 print(\"before\", predicted_unary.item(), cycle_correct[predicted_unary.item()].item())\n",
    "                cycle_correct[i].add_(1)\n",
    "#                 print(\"after\", predicted_unary.item(), cycle_correct[predicted_unary.item()].item())\n",
    "\n",
    "#         to_print = 1\n",
    "#         print(\"image: \", \n",
    "#               image_ERR()[to_print].min().item(), \n",
    "#               image_ERR()[to_print].max().item(),\n",
    "#               image_ERR()[to_print].mul(image_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc1:   \", \n",
    "#               fc1_ERR()[to_print].min().item(), \n",
    "#               fc1_ERR()[to_print].max().item(), \n",
    "#               fc1_ERR()[to_print].mul(fc1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"relu1: \", \n",
    "#               relu1_ERR()[to_print].min().item(), \n",
    "#               relu1_ERR()[to_print].max().item(), \n",
    "#               relu1_ERR()[to_print].mul(relu1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc2:   \", \n",
    "#               fc2_ERR()[to_print].min().item(), \n",
    "#               fc2_ERR()[to_print].max().item(), \n",
    "#               fc2_ERR()[to_print].mul(fc2_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"relu1: \", \n",
    "#               relu2_ERR()[to_print].min().item(), \n",
    "#               relu2_ERR()[to_print].max().item(), \n",
    "#               relu1_ERR()[to_print].mul(relu1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc3:   \", \n",
    "#               fc3_ERR()[to_print].min().item(), \n",
    "#               fc3_ERR()[to_print].max().item(), \n",
    "#               fc3_ERR()[to_print].mul(fc3_ERR()[to_print]).mean().sqrt().item())\n",
    "        \n",
    "        _, predicted_unary = torch.max(fc3_ERR()[0], 1)\n",
    "        correct_unary += (predicted_unary == labels).sum().item()\n",
    "        if total == sample_cnt:\n",
    "            break\n",
    "\n",
    "print('Accuracy of the network on %d test images: %f %%' % (total,\n",
    "    100 * correct_binary / total))\n",
    "print('Accuracy of the network on %d test images: %f %%' % (total,\n",
    "    100 * correct_unary / total))\n",
    "\n",
    "result = cycle_correct.cpu().numpy()/total\n",
    "fig = plt.plot([i for i in range(2**bitwidth)], result)  # arguments are passed to np.histogram\n",
    "plt.title(\"Cycle level accuracy\")\n",
    "plt.show()\n",
    "\n",
    "with open(\"cycle_accuracy_mlp_nonscaled_clamp_gaines.csv\", \"w+\") as f:\n",
    "    for i in result:\n",
    "        f.write(str(i)+\", \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
