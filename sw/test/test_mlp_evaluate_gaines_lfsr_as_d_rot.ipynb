{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from UnarySim.sw.kernel.nn_utils import *\n",
    "from UnarySim.sw.kernel.linear import *\n",
    "from UnarySim.sw.kernel.relu import UnaryReLU\n",
    "from UnarySim.sw.bitstream.gen import RNG, RNGMulti, SourceGen, BSGen\n",
    "from UnarySim.sw.metric.metric import ProgressiveError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project\\Anaconda3\\Lib\\site-packages\\UnarySim\\sw\\test\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data loader\n",
    "transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test binary model clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.080000 %\n"
     ]
    }
   ],
   "source": [
    "model_path = cwd+\"\\saved_model_state_dict_8_clamp\"\n",
    "model_clamp = MLP3_clamp_eval()\n",
    "model_clamp.to(device)\n",
    "model_clamp.load_state_dict(torch.load(model_path))\n",
    "model_clamp.eval()\n",
    "model_clamp.to(device)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_clamp(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test unary model nonscaled addition - clamp binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready for  1 -th image\n",
      "model ready for  2 -th image\n",
      "model ready for  3 -th image\n",
      "model ready for  4 -th image\n",
      "model ready for  5 -th image\n",
      "model ready for  6 -th image\n",
      "model ready for  7 -th image\n",
      "model ready for  8 -th image\n",
      "model ready for  9 -th image\n",
      "model ready for  10 -th image\n",
      "model ready for  11 -th image\n",
      "model ready for  12 -th image\n",
      "model ready for  13 -th image\n",
      "model ready for  14 -th image\n",
      "model ready for  15 -th image\n",
      "model ready for  16 -th image\n",
      "model ready for  17 -th image\n",
      "model ready for  18 -th image\n",
      "model ready for  19 -th image\n",
      "model ready for  20 -th image\n",
      "model ready for  21 -th image\n",
      "model ready for  22 -th image\n",
      "model ready for  23 -th image\n",
      "model ready for  24 -th image\n",
      "model ready for  25 -th image\n",
      "model ready for  26 -th image\n",
      "model ready for  27 -th image\n",
      "model ready for  28 -th image\n",
      "model ready for  29 -th image\n",
      "model ready for  30 -th image\n",
      "model ready for  31 -th image\n",
      "model ready for  32 -th image\n",
      "model ready for  33 -th image\n",
      "model ready for  34 -th image\n",
      "model ready for  35 -th image\n",
      "model ready for  36 -th image\n",
      "model ready for  37 -th image\n",
      "model ready for  38 -th image\n",
      "model ready for  39 -th image\n",
      "model ready for  40 -th image\n",
      "model ready for  41 -th image\n",
      "model ready for  42 -th image\n",
      "model ready for  43 -th image\n",
      "model ready for  44 -th image\n",
      "model ready for  45 -th image\n",
      "model ready for  46 -th image\n",
      "model ready for  47 -th image\n",
      "model ready for  48 -th image\n",
      "model ready for  49 -th image\n",
      "model ready for  50 -th image\n",
      "model ready for  51 -th image\n",
      "model ready for  52 -th image\n",
      "model ready for  53 -th image\n",
      "model ready for  54 -th image\n",
      "model ready for  55 -th image\n",
      "model ready for  56 -th image\n",
      "model ready for  57 -th image\n",
      "model ready for  58 -th image\n",
      "model ready for  59 -th image\n",
      "model ready for  60 -th image\n",
      "model ready for  61 -th image\n",
      "model ready for  62 -th image\n",
      "model ready for  63 -th image\n",
      "model ready for  64 -th image\n",
      "model ready for  65 -th image\n",
      "model ready for  66 -th image\n",
      "model ready for  67 -th image\n",
      "model ready for  68 -th image\n",
      "model ready for  69 -th image\n",
      "model ready for  70 -th image\n",
      "model ready for  71 -th image\n",
      "model ready for  72 -th image\n",
      "model ready for  73 -th image\n",
      "model ready for  74 -th image\n",
      "model ready for  75 -th image\n",
      "model ready for  76 -th image\n",
      "model ready for  77 -th image\n",
      "model ready for  78 -th image\n",
      "model ready for  79 -th image\n",
      "model ready for  80 -th image\n",
      "model ready for  81 -th image\n",
      "model ready for  82 -th image\n",
      "model ready for  83 -th image\n",
      "model ready for  84 -th image\n",
      "model ready for  85 -th image\n",
      "model ready for  86 -th image\n",
      "model ready for  87 -th image\n",
      "model ready for  88 -th image\n",
      "model ready for  89 -th image\n",
      "model ready for  90 -th image\n",
      "model ready for  91 -th image\n",
      "model ready for  92 -th image\n",
      "model ready for  93 -th image\n",
      "model ready for  94 -th image\n",
      "model ready for  95 -th image\n",
      "model ready for  96 -th image\n",
      "model ready for  97 -th image\n",
      "model ready for  98 -th image\n",
      "model ready for  99 -th image\n",
      "model ready for  100 -th image\n",
      "--- 2729.3570194244385 seconds ---\n",
      "100 images are done!!!\n",
      "Accuracy of the network on 100 test images: 98.000000 %\n",
      "Accuracy of the network on 100 test images: 76.000000 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_binary = 0\n",
    "correct_unary = 0\n",
    "\n",
    "bitwidth = 8\n",
    "total = 0\n",
    "\n",
    "# binary MLP3_clamp weight init\n",
    "rng = \"LFSR\"\n",
    "rng_dim = 1\n",
    "relu_buf_dep = 4\n",
    "mode = \"bipolar\"\n",
    "scaled = False\n",
    "bias = True\n",
    "sample_cnt = 100\n",
    "\n",
    "start_cnt = 0\n",
    "current_index = 0\n",
    "\n",
    "cycle_correct = torch.zeros(2**(bitwidth)).to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        if current_index < start_cnt:\n",
    "            current_index = current_index + 1\n",
    "            continue\n",
    "        current_index = current_index + 1\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # reference binary mlp\n",
    "        outputs_binary = model_clamp(images)\n",
    "        _, predicted_binary = torch.max(outputs_binary.data, 1)\n",
    "        correct_binary += (predicted_binary == labels).sum().item()\n",
    "        \n",
    "#         print(model_clamp.fc1_out.min().item(), model_clamp.fc1_out.max().item())\n",
    "#         print(model_clamp.fc2_out.min().item(), model_clamp.fc2_out.max().item())\n",
    "#         print(model_clamp.fc3_out.min().item(), model_clamp.fc3_out.max().item())\n",
    "\n",
    "\n",
    "        # unary part\n",
    "        # input image check\n",
    "        image = images.view(-1, 32*32)\n",
    "        image_SRC = SourceGen(image, bitwidth=bitwidth, mode=mode)().to(device)\n",
    "        image_RNG = RNG(bitwidth, rng_dim, rng)().to(device)\n",
    "        image_BSG = BSGen(image_SRC, image_RNG).to(device)\n",
    "        image_ERR = ProgressiveError(image, mode=mode).to(device)\n",
    "        \n",
    "        # unary mlp is decomposed into separate layers\n",
    "        fc1_unary = GainesLinear4(32*32, 512, model_clamp.fc1.weight.data, model_clamp.fc1.bias.data, \n",
    "                                 bitwidth=bitwidth, mode=mode, scaled=scaled, bias=bias, depth=bitwidth, rng_idx=2).to(device)\n",
    "        fc1_ERR = ProgressiveError(model_clamp.fc1_out, mode=mode).to(device)\n",
    "        \n",
    "        fc2_unary = GainesLinear4(512, 512, model_clamp.fc2.weight.data, model_clamp.fc2.bias.data, \n",
    "                                 bitwidth=bitwidth, mode=mode, scaled=scaled, bias=bias, depth=bitwidth, rng_idx=3).to(device)\n",
    "        fc2_ERR = ProgressiveError(model_clamp.fc2_out, mode=mode).to(device)\n",
    "\n",
    "        fc3_unary = GainesLinear4(512, 10, model_clamp.fc3.weight.data, model_clamp.fc3.bias.data, \n",
    "                                 bitwidth=bitwidth, mode=mode, scaled=scaled, bias=bias, depth=bitwidth, rng_idx=4).to(device)\n",
    "        fc3_ERR = ProgressiveError(model_clamp.fc3_out, mode=mode).to(device)\n",
    "        \n",
    "        relu1_unary = UnaryReLU(buf_dep=relu_buf_dep, bitwidth=bitwidth, rng=rng).to(device)\n",
    "        relu1_ERR = ProgressiveError(model_clamp.relu1_out, mode=mode).to(device)\n",
    "        \n",
    "        relu2_unary = UnaryReLU(buf_dep=relu_buf_dep, bitwidth=bitwidth, rng=rng).to(device)\n",
    "        relu2_ERR = ProgressiveError(model_clamp.relu2_out, mode=mode).to(device)\n",
    "        \n",
    "        print(\"model ready for \", total, \"-th image\")\n",
    "        \n",
    "        if total%100 == 0:\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            print(total, \"images are done!!!\")\n",
    "\n",
    "#         print(current_index, \"-th image with label\", labels.item(), \", total image count\", total)\n",
    "        for i in range(2**(bitwidth)):\n",
    "            idx = torch.zeros(image_SRC.size()).type(torch.long).to(device)\n",
    "            image_bs = image_BSG(idx + i)\n",
    "            image_ERR.Monitor(image_bs)\n",
    "            # print(image_bs.shape)\n",
    "            # fc1\n",
    "            fc1_unary_out   = fc1_unary(image_bs)\n",
    "#             fc1_ERR.Monitor(fc1_unary_out)\n",
    "            # print(fc1_unary_out.shape)\n",
    "            # relu1\n",
    "            relu1_unary_out = relu1_unary(fc1_unary_out)\n",
    "#             relu1_ERR.Monitor(relu1_unary_out)\n",
    "            # print(relu1_unary_out.shape)\n",
    "            # fc2\n",
    "            fc2_unary_out   = fc2_unary(relu1_unary_out)\n",
    "#             fc2_ERR.Monitor(fc2_unary_out)\n",
    "            # print(fc2_unary_out.shape)\n",
    "            # relu2\n",
    "            relu2_unary_out = relu2_unary(fc2_unary_out)\n",
    "#             relu2_ERR.Monitor(relu2_unary_out)\n",
    "            # print(relu2_unary_out.shape)\n",
    "            # fc3\n",
    "            fc3_unary_out   = fc3_unary(relu2_unary_out)\n",
    "            fc3_ERR.Monitor(fc3_unary_out)\n",
    "            # print(fc3_unary_out.shape)\n",
    "            \n",
    "            _, predicted_unary = torch.max(fc3_ERR()[0], 1)\n",
    "            if predicted_unary == labels:\n",
    "#                 print(current_index, \"-th image succeeds.\")\n",
    "#                 print(current_index, \"-th image with label\", labels.item(), \", total image count\", total)\n",
    "#                 print(\"before\", predicted_unary.item(), cycle_correct[predicted_unary.item()].item())\n",
    "                cycle_correct[i].add_(1)\n",
    "#                 print(\"after\", predicted_unary.item(), cycle_correct[predicted_unary.item()].item())\n",
    "\n",
    "#         to_print = 1\n",
    "#         print(\"image: \", \n",
    "#               image_ERR()[to_print].min().item(), \n",
    "#               image_ERR()[to_print].max().item(),\n",
    "#               image_ERR()[to_print].mul(image_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc1:   \", \n",
    "#               fc1_ERR()[to_print].min().item(), \n",
    "#               fc1_ERR()[to_print].max().item(), \n",
    "#               fc1_ERR()[to_print].mul(fc1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"relu1: \", \n",
    "#               relu1_ERR()[to_print].min().item(), \n",
    "#               relu1_ERR()[to_print].max().item(), \n",
    "#               relu1_ERR()[to_print].mul(relu1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc2:   \", \n",
    "#               fc2_ERR()[to_print].min().item(), \n",
    "#               fc2_ERR()[to_print].max().item(), \n",
    "#               fc2_ERR()[to_print].mul(fc2_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"relu1: \", \n",
    "#               relu2_ERR()[to_print].min().item(), \n",
    "#               relu2_ERR()[to_print].max().item(), \n",
    "#               relu1_ERR()[to_print].mul(relu1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc3:   \", \n",
    "#               fc3_ERR()[to_print].min().item(), \n",
    "#               fc3_ERR()[to_print].max().item(), \n",
    "#               fc3_ERR()[to_print].mul(fc3_ERR()[to_print]).mean().sqrt().item())\n",
    "        \n",
    "        _, predicted_unary = torch.max(fc3_ERR()[0], 1)\n",
    "        correct_unary += (predicted_unary == labels).sum().item()\n",
    "        if total == sample_cnt:\n",
    "            break\n",
    "\n",
    "print('Accuracy of the network on %d test images: %f %%' % (total,\n",
    "    100 * correct_binary / total))\n",
    "print('Accuracy of the network on %d test images: %f %%' % (total,\n",
    "    100 * correct_unary / total))\n",
    "\n",
    "result = cycle_correct.cpu().numpy()/total\n",
    "fig = plt.plot([i for i in range(2**bitwidth)], result)  # arguments are passed to np.histogram\n",
    "plt.title(\"Cycle level accuracy\")\n",
    "plt.show()\n",
    "\n",
    "with open(\"cycle_accuracy_mlp_nonscaled_clamp_gaines_lfsr_as_d_rot.csv\", \"w+\") as f:\n",
    "    for i in result:\n",
    "        f.write(str(i)+\", \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
