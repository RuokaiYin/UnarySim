{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch # import main library\n",
    "import torch.nn as nn # import modules like nn.ReLU()\n",
    "import torch.nn.functional as F # import torch functions like F.relu() and F.relu_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_allocated(device, inplace = False):\n",
    "    '''\n",
    "    Function measures allocated memory before and after the ReLU function call.\n",
    "    INPUT:\n",
    "      - device: gpu device to run the operation\n",
    "      - inplace: True - to run ReLU in-place, False - for normal ReLU call\n",
    "    '''\n",
    "    \n",
    "    # Create a large tensor\n",
    "    t = torch.randn(10000, 10000, device=device)\n",
    "    \n",
    "    # Measure allocated memory\n",
    "    torch.cuda.synchronize()\n",
    "    start_max_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
    "    start_memory = torch.cuda.memory_allocated() / 1024**2\n",
    "    \n",
    "    # Call in-place or normal ReLU\n",
    "    if inplace:\n",
    "        # F.relu_(t)\n",
    "        t.mul_(2).div_(5).mul_(7).div_(11)\n",
    "    else:\n",
    "        # output = F.relu(t)\n",
    "        output = t.mul(2).div(5).mul(7).div(11)\n",
    "    \n",
    "    # Measure allocated memory after the call\n",
    "    torch.cuda.synchronize()\n",
    "    end_max_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
    "    end_memory = torch.cuda.memory_allocated() / 1024**2\n",
    "    \n",
    "    # Return amount of memory allocated for ReLU call\n",
    "    return end_memory - start_memory, end_max_memory - start_max_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 382.0\n",
      "Allocated max memory: 764.0\n"
     ]
    }
   ],
   "source": [
    "# call the function to measure allocated memory\n",
    "memory_allocated, max_memory_allocated = get_memory_allocated(device, inplace = False)\n",
    "print('Allocated memory: {}'.format(memory_allocated))\n",
    "print('Allocated max memory: {}'.format(max_memory_allocated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.0\n",
      "Allocated max memory: 0.0\n"
     ]
    }
   ],
   "source": [
    "memory_allocated_inplace, max_memory_allocated_inplace = get_memory_allocated(device, inplace = True)\n",
    "print('Allocated memory: {}'.format(memory_allocated_inplace))\n",
    "print('Allocated max memory: {}'.format(max_memory_allocated_inplace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.Parameter(torch.Tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REFF(torch.nn.Module):\n",
    "    def __init__(self, input):\n",
    "        super(REFF, self).__init__()\n",
    "        self.input = input\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "asad = REFF(torch.Tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REFF()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asad().mul(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asad().mul_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor [1, 1, 3], src [1, 3, 3] and index [1, 1, 3] to have the same size apart from dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-734ba75be2c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0midx_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0midx_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx_u\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor [1, 1, 3], src [1, 3, 3] and index [1, 1, 3] to have the same size apart from dimension 0"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "dim = 0\n",
    "idx = torch.tensor([1, 2, 0])\n",
    "idx_u = torch.unsqueeze(idx, dim)\n",
    "idx_u = torch.unsqueeze(idx_u, dim)\n",
    "torch.gather(t, dim, idx_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 1],\n",
       "        [5, 6, 4],\n",
       "        [8, 9, 7]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "idx = torch.tensor([1, 2, 0])\n",
    "torch.index_select(t, 1, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is tensor\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "# torch.full_like(t, t)\n",
    "\n",
    "if torch.is_tensor(t):\n",
    "    print(\"is tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 30], device='cuda:0', dtype=torch.uint8)\n",
      "tensor([20, 30], device='cuda:0', dtype=torch.uint8)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "_th_dot not supported on CUDAType for Byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-391a5e324ea4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: _th_dot not supported on CUDAType for Byte"
     ]
    }
   ],
   "source": [
    "m=torch.tensor([20,30],dtype=torch.int8).cuda()\n",
    "print(m)\n",
    "a=torch.tensor([20,30],dtype=torch.int8).cuda()\n",
    "print(a)\n",
    "out=torch.matmul(m,a)\n",
    "print(out)\n",
    "print((30*30)%128)\n",
    "input = torch.randint(128,(128,20))\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.arange(3, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=uint8)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int8(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-86-510436aafd8f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-86-510436aafd8f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    z*z'\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "z*z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.arange(3, dtype=np.int8)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz = np.arange(3, dtype=np.int8).transpose()\n",
    "zz = zz.transpose()\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.matmul(z, zz)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1, 70], dtype=torch.int8)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_tensor = torch.tensor([0, 1, 70], dtype=torch.int8)\n",
    "z_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(141, dtype=torch.int32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.matmul(z_tensor, zz, dtype=np.long)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-55 -55 -55 -55 -55] int8\n",
      "tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.int8) torch.int8\n",
      "[201 201 201 201 201] int32\n",
      "[201 201 201 201 201] int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "a = np.ones(5, dtype=np.int8)\n",
    "b = torch.from_numpy(a).cuda()\n",
    "np.add(a, 200, out=a)\n",
    "c = cp.add(b, 200, dtype=np.long)\n",
    "d = cp.asnumpy(c)\n",
    "print(a, a.dtype)\n",
    "print(b, b.dtype)\n",
    "print(c, c.dtype)\n",
    "print(d, d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.6994, -0.4028,  0.1399, -0.7811],\n",
      "          [ 1.7507, -0.8343, -1.2957,  0.1082],\n",
      "          [-1.1536, -0.0152,  0.4139, -0.0038]],\n",
      "\n",
      "         [[ 0.1857, -1.9823,  1.9646, -0.6463],\n",
      "          [ 1.0095, -0.8252, -0.4729, -2.3850],\n",
      "          [ 1.0860,  0.7110,  2.0338, -0.7321]]]], device='cuda:0')\n",
      "<capsule object \"dltensor\" at 0x0000021B7759C1E0>\n",
      "[[[[ 0.69937533 -0.4028198   0.13987271 -0.7810692 ]\n",
      "   [ 1.7507151  -0.8343048  -1.2956558   0.10817128]\n",
      "   [-1.1535931  -0.01519314  0.41391876 -0.00376891]]\n",
      "\n",
      "  [[ 0.18566468 -1.9822772   1.9646336  -0.64633405]\n",
      "   [ 1.009459   -0.825228   -0.47285154 -2.385043  ]\n",
      "   [ 1.0859524   0.71101904  2.0338094  -0.7320675 ]]]]\n",
      "tensor([[[[ 0.6994, -0.4028,  0.1399, -0.7811],\n",
      "          [ 1.7507, -0.8343, -1.2957,  0.1082],\n",
      "          [-1.1536, -0.0152,  0.4139, -0.0038]],\n",
      "\n",
      "         [[ 0.1857, -1.9823,  1.9646, -0.6463],\n",
      "          [ 1.0095, -0.8252, -0.4729, -2.3850],\n",
      "          [ 1.0860,  0.7110,  2.0338, -0.7321]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cupy\n",
    "\n",
    "from torch.utils.dlpack import to_dlpack\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "\n",
    "# Create a PyTorch tensor.\n",
    "tx1 = torch.randn(1, 2, 3, 4).cuda()\n",
    "print(tx1)\n",
    "\n",
    "# Convert it into a DLPack tensor.\n",
    "dx = to_dlpack(tx1)\n",
    "print(dx)\n",
    "\n",
    "# Convert it into a CuPy array.\n",
    "cx = cupy.fromDlpack(dx)\n",
    "print(cx)\n",
    "\n",
    "# Convert it back to a PyTorch tensor.\n",
    "tx2 = from_dlpack(cx.toDlpack())\n",
    "print(tx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "torch.gt(torch.sum(input, 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4], dtype=torch.int8)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.nn.Parameter(torch.tensor([1.]).type(torch.int8), requires_grad=False)\n",
    "a<<2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4],\n",
       "        [ 6,  8],\n",
       "        [10, 12]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input << 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.25499963760375977 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "a_fp = torch.rand(20000, 10000).cuda()\n",
    "b_fp = torch.rand(10000, 40000).cuda()\n",
    "start_time = time.time()\n",
    "c_fp = torch.matmul(a_fp, b_fp)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.2590007781982422 seconds ---\n",
      "<capsule object \"dltensor\" at 0x0000014840F5AED0> <capsule object \"dltensor\" at 0x00000148B13DF360>\n",
      "(20000, 10000) (10000, 40000)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "matmul() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-386bba051a9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_fx_cp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_fx_cp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mc_fx_cp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_fx_cp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_fx_cp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mc_fx_dl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_fx_cp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoDlpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mcupy\\core\\core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.matmul\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: matmul() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "a_fp = torch.rand(20000, 10000).cuda()\n",
    "b_fp = torch.rand(10000, 40000).cuda()\n",
    "start_time = time.time()\n",
    "c_fp = torch.matmul(a_fp, b_fp)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from torch.utils.dlpack import to_dlpack\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "a_fx = torch.randint_like(a_fp, high=15, dtype=torch.int8).cuda()\n",
    "b_fx = torch.randint_like(b_fp, high=15, dtype=torch.int8).cuda()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# # Convert it into a DLPack tensor.\n",
    "a_fx_dl = to_dlpack(a_fx)\n",
    "b_fx_dl = to_dlpack(b_fx)\n",
    "print(a_fx_dl, b_fx_dl)\n",
    "\n",
    "# # Convert it into a CuPy array.\n",
    "a_fx_cp = cp.fromDlpack(to_dlpack(a_fx))\n",
    "b_fx_cp = cp.fromDlpack(to_dlpack(b_fx))\n",
    "print(a_fx_cp.shape, b_fx_cp.shape)\n",
    "\n",
    "c_fx_cp = cp.matmul(a_fx_cp, b_fx_cp, dtype=cp.int32)\n",
    "\n",
    "c_fx_dl = c_fx_cp.toDlpack()\n",
    "\n",
    "c_fx = from_dlpack(c_fx_cp.toDlpack())\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0279998779296875 seconds ---\n",
      "<capsule object \"dltensor\" at 0x000001D0122EBF60> <capsule object \"dltensor\" at 0x000001D03ED302D0>\n",
      "float32 float32\n",
      "--- 0.16499972343444824 seconds ---\n",
      "--- 0.16700005531311035 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "a_fp = torch.rand(20000, 10000).cuda()\n",
    "b_fp = torch.rand(20000, 10000).cuda()\n",
    "start_time = time.time()\n",
    "c_fp = torch.add(a_fp, b_fp)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from torch.utils.dlpack import to_dlpack\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "# a_fx = torch.randint_like(a_fp, high=15, dtype=torch.int8).cuda()\n",
    "# b_fx = torch.randint_like(b_fp, high=15, dtype=torch.int8).cuda()\n",
    "a_fx = torch.rand(20000, 10000).cuda()\n",
    "b_fx = torch.rand(20000, 10000).cuda()\n",
    "\n",
    "\n",
    "# # Convert it into a DLPack tensor.\n",
    "a_fx_dl = to_dlpack(a_fx)\n",
    "b_fx_dl = to_dlpack(b_fx)\n",
    "print(a_fx_dl, b_fx_dl)\n",
    "\n",
    "# # Convert it into a CuPy array.\n",
    "a_fx_cp = cp.fromDlpack(to_dlpack(a_fx))\n",
    "b_fx_cp = cp.fromDlpack(to_dlpack(b_fx))\n",
    "print(a_fx_cp.dtype, b_fx_cp.dtype)\n",
    "\n",
    "start_time_2 = time.time()\n",
    "# c_fx_cp = cp.add(a_fx_cp, b_fx_cp, dtype=cp.int8)\n",
    "c_fx_cp = cp.add(a_fx_cp, b_fx_cp)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_2))\n",
    "\n",
    "c_fx_dl = c_fx_cp.toDlpack()\n",
    "\n",
    "c_fx = from_dlpack(c_fx_cp.toDlpack())\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.003998994827270508 seconds ---\n",
      "--- 0.00099945068359375 seconds ---\n",
      "--- 0.0029976367950439453 seconds ---\n",
      "--- 0.00400090217590332 seconds ---\n",
      "--- 0.006998538970947266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "a_fp = torch.rand(20000, 1000).cuda()\n",
    "b_fp = torch.rand(20000, 1000).cuda()\n",
    "start_time = time.time()\n",
    "c_fp = torch.mul(a_fp, b_fp)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "a_int8 = torch.randint_like(a_fp, high=15, dtype=torch.int8).cuda()\n",
    "b_int8 = torch.randint_like(b_fp, high=15, dtype=torch.int8).cuda()\n",
    "start_time = time.time()\n",
    "c_int8 = torch.mul(a_int8, b_int8)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int8_or = a_int8 | b_int8\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"int8 or\")\n",
    "\n",
    "a_int16 = torch.randint_like(a_fp, high=15, dtype=torch.int16).cuda()\n",
    "b_int16 = torch.randint_like(b_fp, high=15, dtype=torch.int16).cuda()\n",
    "start_time = time.time()\n",
    "c_int16 = torch.mul(a_int16, b_int16)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "a_int32 = torch.randint_like(a_fp, high=15, dtype=torch.int32).cuda()\n",
    "b_int32 = torch.randint_like(b_fp, high=15, dtype=torch.int32).cuda()\n",
    "start_time = time.time()\n",
    "c_int32 = torch.mul(a_int32, b_int32)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "a_int64 = torch.randint_like(a_fp, high=15, dtype=torch.long).cuda()\n",
    "b_int64 = torch.randint_like(b_fp, high=15, dtype=torch.long).cuda()\n",
    "start_time = time.time()\n",
    "c_int64 = torch.mul(a_int64, b_int64)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp add\n",
      "--- 0.003998279571533203 seconds ---\n",
      "int8 add\n",
      "--- 0.0009987354278564453 seconds ---\n",
      "int8 or\n",
      "--- 0.00099945068359375 seconds ---\n",
      "int8 &\n",
      "--- 0.0010006427764892578 seconds ---\n",
      "int16 add\n",
      "--- 0.001991748809814453 seconds ---\n",
      "int16 or\n",
      "--- 0.003000020980834961 seconds ---\n",
      "int16 &\n",
      "--- 0.0019991397857666016 seconds ---\n",
      "int32 add\n",
      "--- 0.00400090217590332 seconds ---\n",
      "int32 or\n",
      "--- 0.003999948501586914 seconds ---\n",
      "int32 &\n",
      "--- 0.004998683929443359 seconds ---\n",
      "int64 add\n",
      "--- 0.0069997310638427734 seconds ---\n",
      "int64 or\n",
      "--- 0.006998777389526367 seconds ---\n",
      "int64 &\n",
      "--- 0.006999015808105469 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "a_fp = torch.rand(20000, 1000).cuda()\n",
    "b_fp = torch.rand(20000, 1000).cuda()\n",
    "start_time = time.time()\n",
    "c_fp = torch.add(a_fp, b_fp)\n",
    "end_time = time.time()\n",
    "print(\"fp add\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "a_int8 = torch.randint_like(a_fp, high=15, dtype=torch.int8).cuda()\n",
    "b_int8 = torch.randint_like(b_fp, high=15, dtype=torch.int8).cuda()\n",
    "start_time = time.time()\n",
    "c_int8 = torch.add(a_int8, b_int8)\n",
    "end_time = time.time()\n",
    "print(\"int8 add\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int8_or = a_int8 | b_int8\n",
    "end_time = time.time()\n",
    "print(\"int8 or\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int8_or = a_int8 & b_int8\n",
    "end_time = time.time()\n",
    "print(\"int8 &\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "a_int16 = torch.randint_like(a_fp, high=15, dtype=torch.int16).cuda()\n",
    "b_int16 = torch.randint_like(b_fp, high=15, dtype=torch.int16).cuda()\n",
    "start_time = time.time()\n",
    "c_int16 = torch.add(a_int16, b_int16)\n",
    "end_time = time.time()\n",
    "print(\"int16 add\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int16_or = a_int16 | b_int16\n",
    "end_time = time.time()\n",
    "print(\"int16 or\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int16_or = a_int16 & b_int16\n",
    "end_time = time.time()\n",
    "print(\"int16 &\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "a_int32 = torch.randint_like(a_fp, high=15, dtype=torch.int32).cuda()\n",
    "b_int32 = torch.randint_like(b_fp, high=15, dtype=torch.int32).cuda()\n",
    "start_time = time.time()\n",
    "c_int32 = torch.add(a_int32, b_int32)\n",
    "end_time = time.time()\n",
    "print(\"int32 add\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int32_or = a_int32 | b_int32\n",
    "end_time = time.time()\n",
    "print(\"int32 or\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int32_or = a_int32 & b_int32\n",
    "end_time = time.time()\n",
    "print(\"int32 &\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "a_int64 = torch.randint_like(a_fp, high=15, dtype=torch.long).cuda()\n",
    "b_int64 = torch.randint_like(b_fp, high=15, dtype=torch.long).cuda()\n",
    "start_time = time.time()\n",
    "c_int64 = torch.add(a_int64, b_int64)\n",
    "end_time = time.time()\n",
    "print(\"int64 add\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int64_or = a_int64 | b_int64\n",
    "end_time = time.time()\n",
    "print(\"int64 or\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c_int64_or = a_int64 & b_int64\n",
    "end_time = time.time()\n",
    "print(\"int64 &\")\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.004999876022338867 seconds ---\n",
      "--- 0.011988639831542969 seconds ---\n",
      "--- 0.007999897003173828 seconds ---\n",
      "--- 0.008999347686767578 seconds ---\n",
      "--- 0.011000394821166992 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "a_fp = torch.rand(20000, 1000).cuda()\n",
    "b_fp = torch.rand(20000, 1000).cuda()\n",
    "start_time = time.time()\n",
    "a_fp = a_fp.type(torch.float)\n",
    "b_fp = b_fp.type(torch.float)\n",
    "c_fp = torch.add(a_fp, b_fp)\n",
    "c_fp = c_fp.type(torch.float)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "a_int8 = torch.randint_like(a_fp, high=15, dtype=torch.int8).cuda()\n",
    "b_int8 = torch.randint_like(b_fp, high=15, dtype=torch.int8).cuda()\n",
    "start_time = time.time()\n",
    "c_int8 = torch.add(a_int8.to(torch.float), b_int8.to(torch.float)).to(torch.int8)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "a_int16 = torch.randint_like(a_fp, high=15, dtype=torch.int16).cuda()\n",
    "b_int16 = torch.randint_like(b_fp, high=15, dtype=torch.int16).cuda()\n",
    "start_time = time.time()\n",
    "c_int16 = torch.add(a_int16.to(torch.float), b_int16.to(torch.float)).to(torch.int16)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "a_int32 = torch.randint_like(a_fp, high=15, dtype=torch.int32).cuda()\n",
    "b_int32 = torch.randint_like(b_fp, high=15, dtype=torch.int32).cuda()\n",
    "start_time = time.time()\n",
    "c_int32 = torch.add(a_int32.to(torch.float), b_int32.to(torch.float)).to(torch.int32)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "a_int64 = torch.randint_like(a_fp, high=15, dtype=torch.long).cuda()\n",
    "b_int64 = torch.randint_like(b_fp, high=15, dtype=torch.long).cuda()\n",
    "start_time = time.time()\n",
    "c_int64 = torch.add(a_int64.to(torch.float), b_int64.to(torch.float)).to(torch.long)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cbitand is only supported for integer type tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:30",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d9c7b41f8114>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: cbitand is only supported for integer type tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:30"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(1.).type(torch.float)\n",
    "b = torch.tensor(3.).type(torch.float)\n",
    "a & b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [5]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "output = torch.index_select(input, 1, torch.tensor([0]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([1, 2, 3, 4])\n",
    "input[1].view(1).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7201, 0.7553, 0.0919, 0.2816, 0.8680, 0.6793, 0.3825, 0.7190],\n",
      "        [0.5422, 0.2417, 0.6755, 0.5620, 0.7300, 0.0159, 0.8989, 0.2788],\n",
      "        [0.1731, 0.8005, 0.0167, 0.0214, 0.6817, 0.1025, 0.7766, 0.3073],\n",
      "        [0.5682, 0.0563, 0.1976, 0.7663, 0.6586, 0.2876, 0.5762, 0.8089],\n",
      "        [0.1996, 0.3268, 0.7525, 0.7614, 0.4310, 0.7391, 0.2393, 0.8521],\n",
      "        [0.7983, 0.2749, 0.4079, 0.1448, 0.3981, 0.1586, 0.4099, 0.7021],\n",
      "        [0.4761, 0.6948, 0.9999, 0.6421, 0.2868, 0.3003, 0.0630, 0.2520],\n",
      "        [0.5110, 0.4397, 0.7171, 0.3433, 0.5921, 0.4132, 0.2102, 0.7366]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "kernel_fr_wr = torch.nn.Linear(8, 8, bias=False)\n",
    "rand = torch.rand(8, 8)\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ed017182cdfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkernel_fr_wr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\project\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    589\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 591\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "kernel_fr_wr.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_fr_wr.data = rand.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4062, 0.7433, 0.8751, 0.9188, 0.8944, 0.3565, 0.5088, 0.1906],\n",
      "        [0.8360, 0.5728, 0.4672, 0.6709, 0.5392, 0.1296, 0.5599, 0.9904],\n",
      "        [0.7828, 0.8184, 0.6564, 0.0988, 0.4593, 0.5735, 0.7389, 0.0227],\n",
      "        [0.1369, 0.3612, 0.5816, 0.6437, 0.6907, 0.8973, 0.2876, 0.9357],\n",
      "        [0.5889, 0.9984, 0.0681, 0.4762, 0.5544, 0.8615, 0.0779, 0.8091],\n",
      "        [0.1926, 0.0929, 0.3711, 0.0054, 0.3269, 0.3530, 0.0945, 0.0524],\n",
      "        [0.0583, 0.7935, 0.3719, 0.8504, 0.8415, 0.7351, 0.2007, 0.3800],\n",
      "        [0.5952, 0.3264, 0.5338, 0.1212, 0.2983, 0.0307, 0.5376, 0.1630]])\n"
     ]
    }
   ],
   "source": [
    "print(kernel_fr_wr.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand[0, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7433, 0.8751, 0.9188, 0.8944, 0.3565, 0.5088, 0.1906],\n",
       "        [0.8360, 0.5728, 0.4672, 0.6709, 0.5392, 0.1296, 0.5599, 0.9904],\n",
       "        [0.7828, 0.8184, 0.6564, 0.0988, 0.4593, 0.5735, 0.7389, 0.0227],\n",
       "        [0.1369, 0.3612, 0.5816, 0.6437, 0.6907, 0.8973, 0.2876, 0.9357],\n",
       "        [0.5889, 0.9984, 0.0681, 0.4762, 0.5544, 0.8615, 0.0779, 0.8091],\n",
       "        [0.1926, 0.0929, 0.3711, 0.0054, 0.3269, 0.3530, 0.0945, 0.0524],\n",
       "        [0.0583, 0.7935, 0.3719, 0.8504, 0.8415, 0.7351, 0.2007, 0.3800],\n",
       "        [0.5952, 0.3264, 0.5338, 0.1212, 0.2983, 0.0307, 0.5376, 0.1630]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4062, 0.7433, 0.8751, 0.9188, 0.8944, 0.3565, 0.5088, 0.1906],\n",
      "        [0.8360, 0.5728, 0.4672, 0.6709, 0.5392, 0.1296, 0.5599, 0.9904],\n",
      "        [0.7828, 0.8184, 0.6564, 0.0988, 0.4593, 0.5735, 0.7389, 0.0227],\n",
      "        [0.1369, 0.3612, 0.5816, 0.6437, 0.6907, 0.8973, 0.2876, 0.9357],\n",
      "        [0.5889, 0.9984, 0.0681, 0.4762, 0.5544, 0.8615, 0.0779, 0.8091],\n",
      "        [0.1926, 0.0929, 0.3711, 0.0054, 0.3269, 0.3530, 0.0945, 0.0524],\n",
      "        [0.0583, 0.7935, 0.3719, 0.8504, 0.8415, 0.7351, 0.2007, 0.3800],\n",
      "        [0.5952, 0.3264, 0.5338, 0.1212, 0.2983, 0.0307, 0.5376, 0.1630]])\n"
     ]
    }
   ],
   "source": [
    "print(kernel_fr_wr.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.+26.j, 0.+32.j]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = [[1+1j, 2+2j]]\n",
    "b = [[3+3j, 4+4j],\n",
    "     [5+5j, 6+6j]]\n",
    "np.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1+1j)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = 1.\n",
    "b = 1.\n",
    "c = a + b * 1.j\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "--- 0.009987592697143555 seconds ---\n",
      "mul\n",
      "--- 0.013000011444091797 seconds ---\n",
      "div\n",
      "--- 0.013998746871948242 seconds ---\n",
      "log\n",
      "--- 0.03499937057495117 seconds ---\n",
      "exp\n",
      "--- 0.012998580932617188 seconds ---\n",
      "softmax\n",
      "--- 0.11499810218811035 seconds ---\n",
      "log_softmax\n",
      "--- 0.10800004005432129 seconds ---\n",
      "tanh\n",
      "--- 0.0149993896484375 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "a = torch.randn(10000000)\n",
    "b = torch.randn(10000000)\n",
    "\n",
    "start_time = time.time()\n",
    "c = a + b\n",
    "print(\"add\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = a * b\n",
    "print(\"mul\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = a / b\n",
    "print(\"div\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.log(a)\n",
    "print(\"log\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.exp(a)\n",
    "print(\"exp\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.softmax(a,dim=0)\n",
    "print(\"softmax\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.log_softmax(a,dim=0)\n",
    "print(\"log_softmax\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.tanh(a)\n",
    "print(\"tanh\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "--- 0.0009999275207519531 seconds ---\n",
      "mul\n",
      "--- 0.0009989738464355469 seconds ---\n",
      "div\n",
      "--- 0.0010001659393310547 seconds ---\n",
      "log\n",
      "--- 0.0 seconds ---\n",
      "exp\n",
      "--- 0.0010025501251220703 seconds ---\n",
      "softmax\n",
      "--- 0.0009970664978027344 seconds ---\n",
      "log_softmax\n",
      "--- 0.0019998550415039062 seconds ---\n",
      "tanh\n",
      "--- 0.0009980201721191406 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "a = torch.randn(10000000).cuda()\n",
    "b = torch.randn(10000000).cuda()\n",
    "\n",
    "start_time = time.time()\n",
    "c = a + b\n",
    "print(\"add\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = a * b\n",
    "print(\"mul\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = a / b\n",
    "print(\"div\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.log(a)\n",
    "print(\"log\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.exp(a)\n",
    "print(\"exp\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.softmax(a,dim=0)\n",
    "print(\"softmax\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.log_softmax(a,dim=0)\n",
    "print(\"log_softmax\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "c = torch.tanh(a)\n",
    "print(\"tanh\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "rand = torch.rand(8, 8)\n",
    "print(rand.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "tensor([[7, 7, 6, 4],\n",
      "        [4, 7, 2, 3],\n",
      "        [2, 6, 6, 7],\n",
      "        [4, 2, 6, 6],\n",
      "        [1, 0, 1, 1],\n",
      "        [4, 2, 1, 6],\n",
      "        [1, 7, 5, 0],\n",
      "        [7, 2, 1, 2]])\n",
      "torch.Size([8])\n",
      "tensor([3, 6, 5, 7, 2, 6, 5, 6])\n",
      "torch.Size([8, 4])\n",
      "tensor([[6, 6, 5, 2],\n",
      "        [2, 6, 5, 7],\n",
      "        [5, 5, 5, 6],\n",
      "        [2, 5, 5, 5],\n",
      "        [6, 3, 6, 6],\n",
      "        [2, 5, 6, 5],\n",
      "        [6, 6, 6, 3],\n",
      "        [6, 5, 6, 5]])\n",
      "torch.Size([8, 4])\n",
      "torch.Size([8, 4, 4])\n",
      "tensor([[[0, 2, 1, 6],\n",
      "         [0, 2, 1, 6],\n",
      "         [5, 6, 5, 0],\n",
      "         [7, 4, 7, 4]],\n",
      "\n",
      "        [[7, 4, 7, 4],\n",
      "         [0, 2, 1, 6],\n",
      "         [5, 6, 5, 0],\n",
      "         [0, 7, 7, 2]],\n",
      "\n",
      "        [[5, 6, 5, 0],\n",
      "         [5, 6, 5, 0],\n",
      "         [5, 6, 5, 0],\n",
      "         [0, 2, 1, 6]],\n",
      "\n",
      "        [[7, 4, 7, 4],\n",
      "         [5, 6, 5, 0],\n",
      "         [5, 6, 5, 0],\n",
      "         [5, 6, 5, 0]],\n",
      "\n",
      "        [[0, 2, 1, 6],\n",
      "         [2, 2, 6, 4],\n",
      "         [0, 2, 1, 6],\n",
      "         [0, 2, 1, 6]],\n",
      "\n",
      "        [[7, 4, 7, 4],\n",
      "         [5, 6, 5, 0],\n",
      "         [0, 2, 1, 6],\n",
      "         [5, 6, 5, 0]],\n",
      "\n",
      "        [[0, 2, 1, 6],\n",
      "         [0, 2, 1, 6],\n",
      "         [0, 2, 1, 6],\n",
      "         [2, 2, 6, 4]],\n",
      "\n",
      "        [[0, 2, 1, 6],\n",
      "         [5, 6, 5, 0],\n",
      "         [0, 2, 1, 6],\n",
      "         [5, 6, 5, 0]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "idx = torch.rand(8, 4).mul(8).type(torch.long)\n",
    "print(idx.size())\n",
    "print(idx)\n",
    "\n",
    "rng = torch.rand(8).mul(8).type(torch.long)\n",
    "print(rng.size())\n",
    "print(rng)\n",
    "\n",
    "rand_sel = rng[idx]\n",
    "print(rand_sel.size())\n",
    "print(rand_sel)\n",
    "\n",
    "rand = torch.rand(8, 4).mul(8).type(torch.long)\n",
    "print(rand.size())\n",
    "print(rand[rand_sel].size())\n",
    "print(rand[rand_sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "Parameter containing:\n",
      "tensor([[1.9906, 5.2643, 6.2076, 0.7621],\n",
      "        [5.5813, 4.5977, 0.2722, 2.2636],\n",
      "        [7.8556, 3.9316, 6.8534, 7.0511],\n",
      "        [4.5860, 6.3364, 0.3593, 2.3045],\n",
      "        [5.1044, 4.0030, 7.5373, 0.2718],\n",
      "        [0.0476, 1.8115, 2.5584, 3.4637],\n",
      "        [3.8516, 1.3529, 6.8673, 3.8338],\n",
      "        [2.8401, 1.1650, 2.3050, 3.8959]], requires_grad=True)\n",
      "tensor([[1., 5., 6., 0.],\n",
      "        [5., 4., 0., 2.],\n",
      "        [7., 3., 6., 7.],\n",
      "        [4., 6., 0., 2.],\n",
      "        [5., 4., 7., 0.],\n",
      "        [0., 1., 2., 3.],\n",
      "        [3., 1., 6., 3.],\n",
      "        [2., 1., 2., 3.]], grad_fn=<FloorBackward>)\n"
     ]
    }
   ],
   "source": [
    "idx = torch.nn.Parameter(torch.rand(8, 4).mul(8))\n",
    "print(idx.size())\n",
    "print(idx)\n",
    "idx_floor = idx.floor()\n",
    "print(idx_floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UnarySim.sw.bitstream.gen import RNG\n",
    "rng = RNG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([128., 192.,  64.,  96., 224., 160.,  32.,  48., 176., 240., 112.,  80.,\n",
      "        208., 144.,  16.,  24., 152., 216.,  88., 120., 248., 184.,  56.,  40.,\n",
      "        168., 232., 104.,  72., 200., 136.,   8.,  12., 140., 204.,  76., 108.,\n",
      "        236., 172.,  44.,  60., 188., 252., 124.,  92., 220., 156.,  28.,  20.,\n",
      "        148., 212.,  84., 116., 244., 180.,  52.,  36., 164., 228., 100.,  68.,\n",
      "        196., 132.,   4.,   6., 134., 198.,  70., 102., 230., 166.,  38.,  54.,\n",
      "        182., 246., 118.,  86., 214., 150.,  22.,  30., 158., 222.,  94., 126.,\n",
      "        254., 190.,  62.,  46., 174., 238., 110.,  78., 206., 142.,  14.,  10.,\n",
      "        138., 202.,  74., 106., 234., 170.,  42.,  58., 186., 250., 122.,  90.,\n",
      "        218., 154.,  26.,  18., 146., 210.,  82., 114., 242., 178.,  50.,  34.,\n",
      "        162., 226.,  98.,  66., 194., 130.,   2.,   3., 131., 195.,  67.,  99.,\n",
      "        227., 163.,  35.,  51., 179., 243., 115.,  83., 211., 147.,  19.,  27.,\n",
      "        155., 219.,  91., 123., 251., 187.,  59.,  43., 171., 235., 107.,  75.,\n",
      "        203., 139.,  11.,  15., 143., 207.,  79., 111., 239., 175.,  47.,  63.,\n",
      "        191., 255., 127.,  95., 223., 159.,  31.,  23., 151., 215.,  87., 119.,\n",
      "        247., 183.,  55.,  39., 167., 231., 103.,  71., 199., 135.,   7.,   5.,\n",
      "        133., 197.,  69., 101., 229., 165.,  37.,  53., 181., 245., 117.,  85.,\n",
      "        213., 149.,  21.,  29., 157., 221.,  93., 125., 253., 189.,  61.,  45.,\n",
      "        173., 237., 109.,  77., 205., 141.,  13.,   9., 137., 201.,  73., 105.,\n",
      "        233., 169.,  41.,  57., 185., 249., 121.,  89., 217., 153.,  25.,  17.,\n",
      "        145., 209.,  81., 113., 241., 177.,  49.,  33., 161., 225.,  97.,  65.,\n",
      "        193., 129.,   1.,   1.])\n"
     ]
    }
   ],
   "source": [
    "print(rng())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
